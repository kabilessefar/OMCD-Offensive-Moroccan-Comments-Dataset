{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_preparation import  clean\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout, Bidirectional\n",
    "import numpy as np\n",
    "from sklearn.metrics import  classification_report\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ù‡Ø§Ø¯Ùƒ Ø§Ù„Ù…Ø¬Ø±Ù… Ù„ÙŠ Ù‚ØªÙ„ Ø§Ù„Ø·ÙÙ„ Ø¹Ø¯Ù†Ø§Ù† Ø®ØµÙˆ Ù„Ø§Ø¹Ø¯Ø§Ù…</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ø§Ù„Ø·ÙÙ„ Ø¹Ø¯Ù†Ø§Ù†  Ø§Ù„Ù„Ù‡ ÙŠØ±Ø­Ù…Ùˆ  ÙˆÙ„ÙƒÙ†  Ù„Ù† ÙŠØ±ØªØ§Ø­  Ø¹Ø¯Ù†Ø§Ù†...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ø®Ø§ØµÙˆ Ø§Ù„Ø§Ø¹Ø¯Ø§Ù… Ø¨Ø¯ÙˆÙ† Ù†Ù‚Ø§Ø´</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù†Ø·Ø§Ù„Ø¨ Ø¨Ø§Ù„Ø¥Ø¹Ø¯Ø§Ù… Ø«Ù… Ø§Ù„Ø¥Ø¹Ø¯Ø§Ù…</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø±Ø§Ù‡ Ù…Ø²Ø§Ù„ ÙƒÙ†ØªØ³Ù†Ø§Ùˆ ÙÙŠ Ø§Ù„Ø§Ø¹Ø¯Ø§Ù…  Ø§Ø¨ØºÙŠÙ†Ø§ Ø§Ù„Ø§Ø¹Ø¯Ø§Ù… ÙˆÙ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  off\n",
       "0          Ù‡Ø§Ø¯Ùƒ Ø§Ù„Ù…Ø¬Ø±Ù… Ù„ÙŠ Ù‚ØªÙ„ Ø§Ù„Ø·ÙÙ„ Ø¹Ø¯Ù†Ø§Ù† Ø®ØµÙˆ Ù„Ø§Ø¹Ø¯Ø§Ù…    1\n",
       "1  Ø§Ù„Ø·ÙÙ„ Ø¹Ø¯Ù†Ø§Ù†  Ø§Ù„Ù„Ù‡ ÙŠØ±Ø­Ù…Ùˆ  ÙˆÙ„ÙƒÙ†  Ù„Ù† ÙŠØ±ØªØ§Ø­  Ø¹Ø¯Ù†Ø§Ù†...    1\n",
       "2                             Ø®Ø§ØµÙˆ Ø§Ù„Ø§Ø¹Ø¯Ø§Ù… Ø¨Ø¯ÙˆÙ† Ù†Ù‚Ø§Ø´    1\n",
       "3                          Ù†Ø·Ø§Ù„Ø¨ Ø¨Ø§Ù„Ø¥Ø¹Ø¯Ø§Ù… Ø«Ù… Ø§Ù„Ø¥Ø¹Ø¯Ø§Ù…    1\n",
       "4  Ø±Ø§Ù‡ Ù…Ø²Ø§Ù„ ÙƒÙ†ØªØ³Ù†Ø§Ùˆ ÙÙŠ Ø§Ù„Ø§Ø¹Ø¯Ø§Ù…  Ø§Ø¨ØºÙŠÙ†Ø§ Ø§Ù„Ø§Ø¹Ø¯Ø§Ù… ÙˆÙ...    1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"offenssivelabelfinal.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2908</td>\n",
       "      <td>ÙÙ†Ø§Ù†ÙŠÙ† Ø§Ù„ÙƒØ¨Øª ÙˆØ§Ù„ÙØ³Ø§Ø¯ .Ø¹Ù‚Ù„ÙŠØ© Ø¬Ù†Ø³ÙŠØ© Ù„Ø§ ØºÙŠØ±. Ø§Ù„Ø¹Ù...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1055</td>\n",
       "      <td>Ø§Ù„Ø¯Ø¹Ø§Ø±Ø© Ù‡Ø±Ø¨Øª Ù…Ù†Ù‡Ø§ ÙÙŠ Ø§Ù„Ù…Ø­Ù…Ø¯ÙŠØ© Ùˆ Ø³ÙƒÙ†Øª ÙÙŠ Ø¨ÙˆØ²Ù†ÙŠÙ‚...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181</td>\n",
       "      <td>ÙƒÙˆÙ† ØºÙŠØ± Ø®Ø±ÙŠØªÙŠ Ùˆ Ù…Ø¯Ø±ØªÙŠØ´ Ù‡Ø§Ø¯Ø´ÙŠ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4313</td>\n",
       "      <td>Ù„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§ Ù‚ÙˆØ© Ø§Ù„Ø§ Ø¨Ø§Ù„Ù„Ù‡ Ø§Ù„Ø¹Ù„ÙŠ Ø§Ù„Ø¹Ø¸ÙŠÙ… Ù„Ø§ Ø­ÙˆÙ„ Ùˆ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ±Ø­Ù… Ø§Ù„ÙˆØ§Ù„Ø¯ÙŠÙ† Ø¹Ù†Ø¯ÙŠ Ù…Ø´ÙƒÙ„ ÙƒØ¨ÙŠÙŠÙŠÙŠØ± Ùˆ Ù…Ø­ØªØ§Ø¬Ø© ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>79</td>\n",
       "      <td>Ù‡Ø¯Ù‰  Ø¬Ù…Ø¹Ø§Ùƒ Ø´Ø¹Ø± ÙƒØ­Ù„</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>3927</td>\n",
       "      <td>ØªÙÙˆ.. Ø¹Ù„Ù‰ Ø£ØºÙ†ÙŠØ© Ø²Ù…Ù„Ø§ÙˆÙŠØ© Ø¨Ø­Ø§Ù„ Ù…ÙˆÙ„Ø§Ù‡Ø§</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>5955</td>\n",
       "      <td>ÙƒÙˆÙ† Ø®Ø±Ø¬Ø§Øª Ù‡Ø§.ÙŠ ÙƒØ§Ù„Øª Ø§Ù†Ø§ ÙƒÙ†Ø´Ø·Ø­ ÙƒÙˆÙ† Ø¨Ø§Ù† Ù„ÙŠÙƒ Ù…Ø³Ø§Ø¹...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>6936</td>\n",
       "      <td>Ø§Ù„ÙØ¯ÙŠÙˆ Ø²ÙˆÙŠÙ†.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>5640</td>\n",
       "      <td>Ù…Ø³ÙƒÙŠÙ†Ø© Ù‡Ø¯Ø§ Ø§Ù… Ø§Ù„Ù„Ù‡ ÙŠØ§ÙƒÙˆØ§Ù† Ù…Ø¹Ù‡Ø§ Ù…Ø³ÙƒÙŠÙ†Ø© ÙŠØ§Ø±Ø¨ Ø¹ÙÙˆ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6419 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                            comment  off\n",
       "0           2908  ÙÙ†Ø§Ù†ÙŠÙ† Ø§Ù„ÙƒØ¨Øª ÙˆØ§Ù„ÙØ³Ø§Ø¯ .Ø¹Ù‚Ù„ÙŠØ© Ø¬Ù†Ø³ÙŠØ© Ù„Ø§ ØºÙŠØ±. Ø§Ù„Ø¹Ù...    1\n",
       "1           1055  Ø§Ù„Ø¯Ø¹Ø§Ø±Ø© Ù‡Ø±Ø¨Øª Ù…Ù†Ù‡Ø§ ÙÙŠ Ø§Ù„Ù…Ø­Ù…Ø¯ÙŠØ© Ùˆ Ø³ÙƒÙ†Øª ÙÙŠ Ø¨ÙˆØ²Ù†ÙŠÙ‚...    1\n",
       "2            181                       ÙƒÙˆÙ† ØºÙŠØ± Ø®Ø±ÙŠØªÙŠ Ùˆ Ù…Ø¯Ø±ØªÙŠØ´ Ù‡Ø§Ø¯Ø´ÙŠ    1\n",
       "3           4313  Ù„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§ Ù‚ÙˆØ© Ø§Ù„Ø§ Ø¨Ø§Ù„Ù„Ù‡ Ø§Ù„Ø¹Ù„ÙŠ Ø§Ù„Ø¹Ø¸ÙŠÙ… Ù„Ø§ Ø­ÙˆÙ„ Ùˆ...    0\n",
       "4            228  Ø§Ù„Ù„Ù‡ ÙŠØ±Ø­Ù… Ø§Ù„ÙˆØ§Ù„Ø¯ÙŠÙ† Ø¹Ù†Ø¯ÙŠ Ù…Ø´ÙƒÙ„ ÙƒØ¨ÙŠÙŠÙŠÙŠØ± Ùˆ Ù…Ø­ØªØ§Ø¬Ø© ...    0\n",
       "...          ...                                                ...  ...\n",
       "6414          79                                 Ù‡Ø¯Ù‰  Ø¬Ù…Ø¹Ø§Ùƒ Ø´Ø¹Ø± ÙƒØ­Ù„    0\n",
       "6415        3927                ØªÙÙˆ.. Ø¹Ù„Ù‰ Ø£ØºÙ†ÙŠØ© Ø²Ù…Ù„Ø§ÙˆÙŠØ© Ø¨Ø­Ø§Ù„ Ù…ÙˆÙ„Ø§Ù‡Ø§    1\n",
       "6416        5955  ÙƒÙˆÙ† Ø®Ø±Ø¬Ø§Øª Ù‡Ø§.ÙŠ ÙƒØ§Ù„Øª Ø§Ù†Ø§ ÙƒÙ†Ø´Ø·Ø­ ÙƒÙˆÙ† Ø¨Ø§Ù† Ù„ÙŠÙƒ Ù…Ø³Ø§Ø¹...    1\n",
       "6417        6936                                       Ø§Ù„ÙØ¯ÙŠÙˆ Ø²ÙˆÙŠÙ†.    0\n",
       "6418        5640  Ù…Ø³ÙƒÙŠÙ†Ø© Ù‡Ø¯Ø§ Ø§Ù… Ø§Ù„Ù„Ù‡ ÙŠØ§ÙƒÙˆØ§Ù† Ù…Ø¹Ù‡Ø§ Ù…Ø³ÙƒÙŠÙ†Ø© ÙŠØ§Ø±Ø¨ Ø¹ÙÙˆ...    0\n",
       "\n",
       "[6419 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"train.csv\")\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6139</td>\n",
       "      <td>ØªØ¨Ù‡Ø¯ÙŠÙ„ ØªØ³Ø¤Ù„Ùˆ Ø§Ù„Ø¨Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø´Ø§Ø±Ø¹</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3447</td>\n",
       "      <td>Ø§Ù†Ø§ Ù…Ø³ØªØ¹Ø¯ Ø¨ÙŠ Ù…Ø³Ø¹Ø¯Ø© Ø¨Ø³ÙŠØ·Ø© ÙÙŠ ÙˆØ¬Ù‡ Ø§Ù„Ù„Ø© Ø±Ø¨ÙŠ ÙŠØ§Ø¯ÙŠØ±...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6844</td>\n",
       "      <td>Ù„Ø§Ø­ÙˆÙ„ ÙˆÙ„Ø§Ù‚ÙˆØ© Ø§Ù„Ø§ Ø¨Ø§Ù„Ù„Ù‡ Ø§Ù„Ø¹Ù„ÙŠ Ø§Ù„Ø¹Ø¸ÙŠÙ…</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2512</td>\n",
       "      <td>Ø­ØªÙ‰ Ù‡Ø§Ø¯ Ø§Ù„Ø¹Ø§Ø¦Ù„Ø© Ù„ÙŠ Ø¬Ø§Ù„Ø³ ÙˆØ³Ø· Ù…Ù†Ù‡ÙˆÙ… Ø®Øµ ÙŠØ¯Ù„Ù…Ù‡ÙˆÙ… Ø§...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ù„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§ Ù‚ÙˆØ© Ø§Ù„Ø§ Ø¨Ø§Ù„Ù„Ù‡ Ø§Ø´ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§ØµÙ„Ø§ Ø±...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>6470</td>\n",
       "      <td>Ù„ÙŠ Ø¬Ø§ Ù…Ù† Ø¹Ù†Ø¯ Ø¨ÙŠÙ…Ùˆ Ø§Ø®Ø¨Ø· Ù„Ø§ÙŠÙƒ ğŸ˜¹ğŸ˜¹ğŸ˜¹ğŸ˜¹</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>6198</td>\n",
       "      <td>ÙˆÙ†ØªØ³Ø§Ø¡Ù„ Ù„Ù…Ø§Ø¯Ø§ Ø§Ù„Ù„Ù‡ Ø§Ø±Ø³Ù„ Ù„Ù†Ø§ ÙÙŠØ±ÙˆØ³ ÙƒÙˆØ±ÙˆÙ†Ø§</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>3009</td>\n",
       "      <td>Ø®Ø§Ù†Ø²Ø© ÙƒÙŠÙ„ÙˆØ· ÙˆØ§ Ø§Ù„Ø±ÙˆÙŠØ¬Ù„ Ø³ÙŠØ± Ø¯ÙŠØ± Ø§Ù„Ø±Ù‚ÙŠØ© Ù†ØµØ­Ùƒ Ù‡Ø§Ø¯...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>647</td>\n",
       "      <td>Ø³ÙŠØ± Ø§Ù„Ù„Ù‡ ÙŠØ¹ÙÙˆ Ø§Ø¹Ù„ÙŠÙƒ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>1921</td>\n",
       "      <td>Ø¹Ù†Ø¯Ù…Ø§ ØªÙ‚ÙˆÙ…ÙŠÙ† Ø¨Ø¶Ø±Ø¨ Ø£Ø­Ø¯Ù‡Ù… ÙˆØ¨ÙƒÙ„Ø§Ù… ØºÙŠØ± Ù„Ø§Ø¦Ù‚ ÙˆØªÙƒØªØ´Ù...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1605 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                            comment  off\n",
       "0           6139                      ØªØ¨Ù‡Ø¯ÙŠÙ„ ØªØ³Ø¤Ù„Ùˆ Ø§Ù„Ø¨Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø´Ø§Ø±Ø¹    1\n",
       "1           3447  Ø§Ù†Ø§ Ù…Ø³ØªØ¹Ø¯ Ø¨ÙŠ Ù…Ø³Ø¹Ø¯Ø© Ø¨Ø³ÙŠØ·Ø© ÙÙŠ ÙˆØ¬Ù‡ Ø§Ù„Ù„Ø© Ø±Ø¨ÙŠ ÙŠØ§Ø¯ÙŠØ±...    0\n",
       "2           6844                Ù„Ø§Ø­ÙˆÙ„ ÙˆÙ„Ø§Ù‚ÙˆØ© Ø§Ù„Ø§ Ø¨Ø§Ù„Ù„Ù‡ Ø§Ù„Ø¹Ù„ÙŠ Ø§Ù„Ø¹Ø¸ÙŠÙ…    0\n",
       "3           2512  Ø­ØªÙ‰ Ù‡Ø§Ø¯ Ø§Ù„Ø¹Ø§Ø¦Ù„Ø© Ù„ÙŠ Ø¬Ø§Ù„Ø³ ÙˆØ³Ø· Ù…Ù†Ù‡ÙˆÙ… Ø®Øµ ÙŠØ¯Ù„Ù…Ù‡ÙˆÙ… Ø§...    1\n",
       "4           2000  Ù„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§ Ù‚ÙˆØ© Ø§Ù„Ø§ Ø¨Ø§Ù„Ù„Ù‡ Ø§Ø´ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§ØµÙ„Ø§ Ø±...    1\n",
       "...          ...                                                ...  ...\n",
       "1600        6470                   Ù„ÙŠ Ø¬Ø§ Ù…Ù† Ø¹Ù†Ø¯ Ø¨ÙŠÙ…Ùˆ Ø§Ø®Ø¨Ø· Ù„Ø§ÙŠÙƒ ğŸ˜¹ğŸ˜¹ğŸ˜¹ğŸ˜¹    0\n",
       "1601        6198           ÙˆÙ†ØªØ³Ø§Ø¡Ù„ Ù„Ù…Ø§Ø¯Ø§ Ø§Ù„Ù„Ù‡ Ø§Ø±Ø³Ù„ Ù„Ù†Ø§ ÙÙŠØ±ÙˆØ³ ÙƒÙˆØ±ÙˆÙ†Ø§    1\n",
       "1602        3009  Ø®Ø§Ù†Ø²Ø© ÙƒÙŠÙ„ÙˆØ· ÙˆØ§ Ø§Ù„Ø±ÙˆÙŠØ¬Ù„ Ø³ÙŠØ± Ø¯ÙŠØ± Ø§Ù„Ø±Ù‚ÙŠØ© Ù†ØµØ­Ùƒ Ù‡Ø§Ø¯...    1\n",
       "1603         647                                Ø³ÙŠØ± Ø§Ù„Ù„Ù‡ ÙŠØ¹ÙÙˆ Ø§Ø¹Ù„ÙŠÙƒ    0\n",
       "1604        1921  Ø¹Ù†Ø¯Ù…Ø§ ØªÙ‚ÙˆÙ…ÙŠÙ† Ø¨Ø¶Ø±Ø¨ Ø£Ø­Ø¯Ù‡Ù… ÙˆØ¨ÙƒÙ„Ø§Ù… ØºÙŠØ± Ù„Ø§Ø¦Ù‚ ÙˆØªÙƒØªØ´Ù...    1\n",
       "\n",
       "[1605 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"test.csv\")\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"clean_comment\"]=data_train[\"comment\"].apply(lambda row: clean(row))\n",
    "data_test[\"clean_comment\"]=data_test[\"comment\"].apply(lambda row: clean(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_emoji(sent):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_emoji(s):\n",
    "    return s in UNICODE_EMOJI['en']\n",
    "# add space near your emoji\n",
    "def add_space(text):\n",
    "    return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"clean_comment_nemoji\"]=data[\"clean_comment\"].apply(lambda row: replace_emoji(row))\n",
    "data_train[\"clean_comment_nemoji\"]=data_train[\"clean_comment\"].apply(lambda row: replace_emoji(row))\n",
    "data_test[\"clean_comment_nemoji\"]=data_test[\"clean_comment\"].apply(lambda row: replace_emoji(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23924 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(data_train['clean_comment_nemoji'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (6419, 250)\n"
     ]
    }
   ],
   "source": [
    "X_train = tokenizer.texts_to_sequences(data_train['clean_comment_nemoji'].values)\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (1605, 250)\n"
     ]
    }
   ],
   "source": [
    "X_test = tokenizer.texts_to_sequences(data_test['clean_comment_nemoji'].values)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ø³ÙŠØ± Ø§Ù„Ù„Ù‡ Ø§Ù„Ø¹Ù† Ù„Ù…Ø±Ø¨Ø§ÙƒØ´ ØªØ±Ø¨ÙŠÙ‡ Ø­Ø³Ù†Ù‡'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['clean_comment_nemoji'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (6419, 2)\n"
     ]
    }
   ],
   "source": [
    "Y_train = pd.get_dummies(data_train['off']).values\n",
    "print('Shape of label tensor:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (1605, 2)\n"
     ]
    }
   ],
   "source": [
    "Y_test = pd.get_dummies(data_test['off']).values\n",
    "print('Shape of label tensor:', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6419, 250) (6419, 2)\n",
      "(1605, 250) (6419, 2)\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 250, 100)          5000000   \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 250, 100)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,080,602\n",
      "Trainable params: 5,080,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0329 23:14:56.772566 28628 ag_logging.py:146] AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000029D498945E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000029D498945E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "91/91 [==============================] - ETA: 0s - loss: 0.6131 - accuracy: 0.6507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0329 23:15:36.871366 28628 ag_logging.py:146] AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000029D4BCC3280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000029D4BCC3280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "91/91 [==============================] - 41s 419ms/step - loss: 0.6131 - accuracy: 0.6507 - val_loss: 0.5053 - val_accuracy: 0.7555\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 38s 418ms/step - loss: 0.2826 - accuracy: 0.8828 - val_loss: 0.4876 - val_accuracy: 0.7897\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 42s 458ms/step - loss: 0.1065 - accuracy: 0.9633 - val_loss: 0.5856 - val_accuracy: 0.7819\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 40s 439ms/step - loss: 0.0485 - accuracy: 0.9851 - val_loss: 0.6432 - val_accuracy: 0.7835\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 41s 451ms/step - loss: 0.0306 - accuracy: 0.9920 - val_loss: 0.7190 - val_accuracy: 0.7804\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0329 23:19:23.646478 28628 ag_logging.py:146] AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000029D4BF14040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000029D4BF14040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       ...,\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bool = np.argmax(prediction, axis=1)\n",
    "y_pred = (prediction > 0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76       717\n",
      "           1       0.83      0.73      0.78       888\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1605\n",
      "   macro avg       0.77      0.77      0.77      1605\n",
      "weighted avg       0.78      0.77      0.77      1605\n",
      " samples avg       0.77      0.77      0.77      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_bool=np.argmax(Y_test, axis=1)\n",
    "y_test_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7113    0.8145    0.7594       717\n",
      "           1     0.8304    0.7331    0.7787       888\n",
      "\n",
      "    accuracy                         0.7695      1605\n",
      "   macro avg     0.7708    0.7738    0.7691      1605\n",
      "weighted avg     0.7772    0.7695    0.7701      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_bool, y_pred_bool, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BILSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 250, 100)          5000000   \n",
      "                                                                 \n",
      " spatial_dropout1d_6 (Spatia  (None, 250, 100)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 250, 200)         160800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 200)              240800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 402       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,402,002\n",
      "Trainable params: 5,402,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_train.shape[1]))\n",
    "model1.add(SpatialDropout1D(0.2))\n",
    "model1.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))\n",
    "model1.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model1.add(Dense(2, activation='softmax'))\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0331 23:50:55.089491 28628 ag_logging.py:146] AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000029DB5A52EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000029DB5A52EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "91/91 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.6425  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0401 10:07:15.387005 28628 ag_logging.py:146] AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000029D699031F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000029D699031F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "91/91 [==============================] - 36988s 410s/step - loss: 0.6013 - accuracy: 0.6425 - val_loss: 0.5014 - val_accuracy: 0.7632\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 2857s 31s/step - loss: 0.2448 - accuracy: 0.9022 - val_loss: 0.5230 - val_accuracy: 0.7695\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 2789s 31s/step - loss: 0.0812 - accuracy: 0.9716 - val_loss: 0.6854 - val_accuracy: 0.7726\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 2302s 25s/step - loss: 0.0365 - accuracy: 0.9886 - val_loss: 0.7309 - val_accuracy: 0.7632\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "batch_size = 64\n",
    "\n",
    "history1 = model1.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0401 12:19:50.479997 28628 ag_logging.py:146] AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000029D69749040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000029D69749040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       ...,\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bool1 = np.argmax(prediction1, axis=1)\n",
    "y_pred1 = (prediction1 > 0.5)\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7241    0.7978    0.7591       717\n",
      "           1     0.8221    0.7545    0.7868       888\n",
      "\n",
      "   micro avg     0.7738    0.7738    0.7738      1605\n",
      "   macro avg     0.7731    0.7761    0.7730      1605\n",
      "weighted avg     0.7783    0.7738    0.7745      1605\n",
      " samples avg     0.7738    0.7738    0.7738      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred1, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bool1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_bool=np.argmax(Y_test, axis=1)\n",
    "y_test_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7241    0.7978    0.7591       717\n",
      "           1     0.8221    0.7545    0.7868       888\n",
      "\n",
      "    accuracy                         0.7738      1605\n",
      "   macro avg     0.7731    0.7761    0.7730      1605\n",
      "weighted avg     0.7783    0.7738    0.7745      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_bool, y_pred_bool1, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_emoji(s):\n",
    "    return s in UNICODE_EMOJI['en']\n",
    "# add space near your emoji\n",
    "def add_space(text):\n",
    "    return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"clean_comment_nemoji\"]=data[\"clean_comment\"].apply(lambda row: replace_emoji(row))\n",
    "data_train[\"clean_comment_emoji\"]=data_train[\"clean_comment\"].apply(lambda row: add_space(row))\n",
    "data_test[\"clean_comment_emoji\"]=data_test[\"clean_comment\"].apply(lambda row: add_space(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24095 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(data_train['clean_comment_emoji'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (6419, 250)\n"
     ]
    }
   ],
   "source": [
    "X_train = tokenizer.texts_to_sequences(data_train['clean_comment_emoji'].values)\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (1605, 250)\n"
     ]
    }
   ],
   "source": [
    "X_test = tokenizer.texts_to_sequences(data_test['clean_comment_emoji'].values)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ø³ÙŠØ± Ø§Ù„Ù„Ù‡ Ø§Ù„Ø¹Ù† Ù„Ù…Ø±Ø¨Ø§ÙƒØ´ ØªØ±Ø¨ÙŠÙ‡ Ø­Ø³Ù†Ù‡'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['clean_comment_emoji'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (6419, 2)\n"
     ]
    }
   ],
   "source": [
    "Y_train = pd.get_dummies(data_train['off']).values\n",
    "print('Shape of label tensor:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (1605, 2)\n"
     ]
    }
   ],
   "source": [
    "Y_test = pd.get_dummies(data_test['off']).values\n",
    "print('Shape of label tensor:', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6419, 250) (6419, 2)\n",
      "(1605, 250) (1605, 2)\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 250, 100)          5000000   \n",
      "                                                                 \n",
      " spatial_dropout1d_4 (Spatia  (None, 250, 100)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,080,602\n",
      "Trainable params: 5,080,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0330 12:05:28.146663 28628 ag_logging.py:146] AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000029D412BC820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000029D412BC820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "91/91 [==============================] - ETA: 0s - loss: 0.6149 - accuracy: 0.6458"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0330 12:07:07.256742 28628 ag_logging.py:146] AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000029D660A0670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000029D660A0670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "91/91 [==============================] - 100s 1s/step - loss: 0.6149 - accuracy: 0.6458 - val_loss: 0.5010 - val_accuracy: 0.7492\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 95s 1s/step - loss: 0.2898 - accuracy: 0.8811 - val_loss: 0.5037 - val_accuracy: 0.7882\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 96s 1s/step - loss: 0.1050 - accuracy: 0.9619 - val_loss: 0.6283 - val_accuracy: 0.7710\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 101s 1s/step - loss: 0.0492 - accuracy: 0.9853 - val_loss: 0.7116 - val_accuracy: 0.7741\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0330 12:12:01.267088 28628 ag_logging.py:146] AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000029D6615C310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000029D6615C310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       ...,\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bool = np.argmax(prediction, axis=1)\n",
    "y_pred = (prediction > 0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.77       717\n",
      "           1       0.86      0.69      0.77       888\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1605\n",
      "   macro avg       0.78      0.78      0.77      1605\n",
      "weighted avg       0.79      0.77      0.77      1605\n",
      " samples avg       0.77      0.77      0.77      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_bool=np.argmax(Y_test, axis=1)\n",
    "y_test_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6912    0.8647    0.7683       717\n",
      "           1     0.8630    0.6881    0.7657       888\n",
      "\n",
      "    accuracy                         0.7670      1605\n",
      "   macro avg     0.7771    0.7764    0.7670      1605\n",
      "weighted avg     0.7862    0.7670    0.7668      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_bool, y_pred_bool, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BILSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 250, 100)          5000000   \n",
      "                                                                 \n",
      " spatial_dropout1d_5 (Spatia  (None, 250, 100)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 250, 200)         160800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 200)              240800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 402       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,402,002\n",
      "Trainable params: 5,402,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_train.shape[1]))\n",
    "model1.add(SpatialDropout1D(0.2))\n",
    "model1.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))\n",
    "model1.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model1.add(Dense(2, activation='softmax'))\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0330 12:12:06.199584 28628 ag_logging.py:146] AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000029D6E0445E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000029D6E0445E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "91/91 [==============================] - ETA: 0s - loss: 0.6020 - accuracy: 0.6367 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0330 12:30:14.169066 28628 ag_logging.py:146] AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000029DB15E3550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000029DB15E3550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "91/91 [==============================] - 1093s 12s/step - loss: 0.6020 - accuracy: 0.6367 - val_loss: 0.4875 - val_accuracy: 0.7648\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 1509s 17s/step - loss: 0.2473 - accuracy: 0.9048 - val_loss: 0.5271 - val_accuracy: 0.7819\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 2735s 30s/step - loss: 0.0934 - accuracy: 0.9683 - val_loss: 0.6332 - val_accuracy: 0.7664\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 2802s 31s/step - loss: 0.0423 - accuracy: 0.9884 - val_loss: 0.8292 - val_accuracy: 0.7679\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "batch_size = 64\n",
    "\n",
    "history1 = model1.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0330 14:27:45.654215 28628 ag_logging.py:146] AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000029D67563820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000029D67563820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       ...,\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bool1 = np.argmax(prediction1, axis=1)\n",
    "y_pred1 = (prediction1 > 0.5)\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7219    0.7964    0.7573       717\n",
      "           1     0.8206    0.7523    0.7850       888\n",
      "\n",
      "   micro avg     0.7720    0.7720    0.7720      1605\n",
      "   macro avg     0.7713    0.7743    0.7711      1605\n",
      "weighted avg     0.7765    0.7720    0.7726      1605\n",
      " samples avg     0.7720    0.7720    0.7720      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred1, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bool1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_bool=np.argmax(Y_test, axis=1)\n",
    "y_test_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7219    0.7964    0.7573       717\n",
      "           1     0.8206    0.7523    0.7850       888\n",
      "\n",
      "    accuracy                         0.7720      1605\n",
      "   macro avg     0.7713    0.7743    0.7711      1605\n",
      "weighted avg     0.7765    0.7720    0.7726      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_bool, y_pred_bool1, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
