{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re, json, pickle, warnings, nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "# importing the wordCloud\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from bidi.algorithm import get_display\n",
    "import arabic_reshaper\n",
    "from data_preparation import clean_content_aravec, clean\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df= pd.read_csv(\"offenssivelabelfinal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_csv(\"train.csv\")\n",
    "df2= pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1, df2= train_test_split(df, test_size =.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2908</td>\n",
       "      <td>فنانين الكبت والفساد .عقلية جنسية لا غير. العف...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1055</td>\n",
       "      <td>الدعارة هربت منها في المحمدية و سكنت في بوزنيق...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181</td>\n",
       "      <td>كون غير خريتي و مدرتيش هادشي</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4313</td>\n",
       "      <td>لا حول ولا قوة الا بالله العلي العظيم لا حول و...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>الله يرحم الوالدين عندي مشكل كبيييير و محتاجة ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>79</td>\n",
       "      <td>هدى  جمعاك شعر كحل</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>3927</td>\n",
       "      <td>تفو.. على أغنية زملاوية بحال مولاها</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>5955</td>\n",
       "      <td>كون خرجات ها.ي كالت انا كنشطح كون بان ليك مساع...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>6936</td>\n",
       "      <td>الفديو زوين.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>5640</td>\n",
       "      <td>مسكينة هدا ام الله ياكوان معها مسكينة يارب عفو...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6419 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                            comment  off\n",
       "0           2908  فنانين الكبت والفساد .عقلية جنسية لا غير. العف...    1\n",
       "1           1055  الدعارة هربت منها في المحمدية و سكنت في بوزنيق...    1\n",
       "2            181                       كون غير خريتي و مدرتيش هادشي    1\n",
       "3           4313  لا حول ولا قوة الا بالله العلي العظيم لا حول و...    0\n",
       "4            228  الله يرحم الوالدين عندي مشكل كبيييير و محتاجة ...    0\n",
       "...          ...                                                ...  ...\n",
       "6414          79                                 هدى  جمعاك شعر كحل    0\n",
       "6415        3927                تفو.. على أغنية زملاوية بحال مولاها    1\n",
       "6416        5955  كون خرجات ها.ي كالت انا كنشطح كون بان ليك مساع...    1\n",
       "6417        6936                                       الفديو زوين.    0\n",
       "6418        5640  مسكينة هدا ام الله ياكوان معها مسكينة يارب عفو...    0\n",
       "\n",
       "[6419 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6139</td>\n",
       "      <td>تبهديل تسؤلو البنات في الشارع</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3447</td>\n",
       "      <td>انا مستعد بي مسعدة بسيطة في وجه اللة ربي يادير...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6844</td>\n",
       "      <td>لاحول ولاقوة الا بالله العلي العظيم</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2512</td>\n",
       "      <td>حتى هاد العائلة لي جالس وسط منهوم خص يدلمهوم ا...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>لا حول ولا قوة الا بالله اش هذا المستوى اصلا ر...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>6470</td>\n",
       "      <td>لي جا من عند بيمو اخبط لايك 😹😹😹😹</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>6198</td>\n",
       "      <td>ونتساءل لمادا الله ارسل لنا فيروس كورونا</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>3009</td>\n",
       "      <td>خانزة كيلوط وا الرويجل سير دير الرقية نصحك هاد...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>647</td>\n",
       "      <td>سير الله يعفو اعليك</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>1921</td>\n",
       "      <td>عندما تقومين بضرب أحدهم وبكلام غير لائق وتكتشف...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1605 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                            comment  off\n",
       "0           6139                      تبهديل تسؤلو البنات في الشارع    1\n",
       "1           3447  انا مستعد بي مسعدة بسيطة في وجه اللة ربي يادير...    0\n",
       "2           6844                لاحول ولاقوة الا بالله العلي العظيم    0\n",
       "3           2512  حتى هاد العائلة لي جالس وسط منهوم خص يدلمهوم ا...    1\n",
       "4           2000  لا حول ولا قوة الا بالله اش هذا المستوى اصلا ر...    1\n",
       "...          ...                                                ...  ...\n",
       "1600        6470                   لي جا من عند بيمو اخبط لايك 😹😹😹😹    0\n",
       "1601        6198           ونتساءل لمادا الله ارسل لنا فيروس كورونا    1\n",
       "1602        3009  خانزة كيلوط وا الرويجل سير دير الرقية نصحك هاد...    1\n",
       "1603         647                                سير الله يعفو اعليك    0\n",
       "1604        1921  عندما تقومين بضرب أحدهم وبكلام غير لائق وتكتشف...    1\n",
       "\n",
       "[1605 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-18e875878c41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcomments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "comments = ' '.join(list(df.comment))\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment', 'off'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"clean_comment\"]=df1[\"comment\"].apply(lambda row: clean(row))\n",
    "df2[\"clean_comment\"]=df2[\"comment\"].apply(lambda row: clean(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'نوع اخر البشر زوامل الشوهه'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"clean_comment\"][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_emoji(sent):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'نوع اخر البشر زوامل الشوهه'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_emoji(df1[\"clean_comment\"][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"clean_comment_nemoji\"]=df1[\"clean_comment\"].apply(lambda row: replace_emoji(row))\n",
    "df2[\"clean_comment_nemoji\"]=df2[\"clean_comment\"].apply(lambda row: replace_emoji(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'نوع اخر البشر زوامل الشوهه'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"clean_comment_nemoji\"][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>off</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>clean_comment_nemoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2908</td>\n",
       "      <td>فنانين الكبت والفساد .عقلية جنسية لا غير. العف...</td>\n",
       "      <td>1</td>\n",
       "      <td>فنانين الكبت والفساد عقليه جنسيه العفن الفن شع...</td>\n",
       "      <td>فنانين الكبت والفساد عقليه جنسيه العفن الفن شع...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1055</td>\n",
       "      <td>الدعارة هربت منها في المحمدية و سكنت في بوزنيق...</td>\n",
       "      <td>1</td>\n",
       "      <td>الدعاره هربت المحمديه سكنت بوزنيقه بحال بحال م...</td>\n",
       "      <td>الدعاره هربت المحمديه سكنت بوزنيقه بحال بحال م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181</td>\n",
       "      <td>كون غير خريتي و مدرتيش هادشي</td>\n",
       "      <td>1</td>\n",
       "      <td>كون خريتي مدرتيش هادشي</td>\n",
       "      <td>كون خريتي مدرتيش هادشي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4313</td>\n",
       "      <td>لا حول ولا قوة الا بالله العلي العظيم لا حول و...</td>\n",
       "      <td>0</td>\n",
       "      <td>بالله العلي العظيم بالله العلي العظيم استغفرال...</td>\n",
       "      <td>بالله العلي العظيم بالله العلي العظيم استغفرال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>الله يرحم الوالدين عندي مشكل كبيييير و محتاجة ...</td>\n",
       "      <td>0</td>\n",
       "      <td>الله يرحم الوالدين عندي مشكل كبيير محتاجه الدع...</td>\n",
       "      <td>الله يرحم الوالدين عندي مشكل كبيير محتاجه الدع...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>79</td>\n",
       "      <td>هدى  جمعاك شعر كحل</td>\n",
       "      <td>0</td>\n",
       "      <td>هدي جمعاك شعر كحل</td>\n",
       "      <td>هدي جمعاك شعر كحل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>3927</td>\n",
       "      <td>تفو.. على أغنية زملاوية بحال مولاها</td>\n",
       "      <td>1</td>\n",
       "      <td>تفو اغنيه زملاويه بحال مولاها</td>\n",
       "      <td>تفو اغنيه زملاويه بحال مولاها</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>5955</td>\n",
       "      <td>كون خرجات ها.ي كالت انا كنشطح كون بان ليك مساع...</td>\n",
       "      <td>1</td>\n",
       "      <td>كون خرجات هاي كالت انا كنشطح كون ليك مساعادات ...</td>\n",
       "      <td>كون خرجات هاي كالت انا كنشطح كون ليك مساعادات ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>6936</td>\n",
       "      <td>الفديو زوين.</td>\n",
       "      <td>0</td>\n",
       "      <td>الفديو زوين</td>\n",
       "      <td>الفديو زوين</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>5640</td>\n",
       "      <td>مسكينة هدا ام الله ياكوان معها مسكينة يارب عفو...</td>\n",
       "      <td>0</td>\n",
       "      <td>مسكينه هدا ام الله ياكوان مسكينه يارب عفو بنته...</td>\n",
       "      <td>مسكينه هدا ام الله ياكوان مسكينه يارب عفو بنته...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6419 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                            comment  off  \\\n",
       "0           2908  فنانين الكبت والفساد .عقلية جنسية لا غير. العف...    1   \n",
       "1           1055  الدعارة هربت منها في المحمدية و سكنت في بوزنيق...    1   \n",
       "2            181                       كون غير خريتي و مدرتيش هادشي    1   \n",
       "3           4313  لا حول ولا قوة الا بالله العلي العظيم لا حول و...    0   \n",
       "4            228  الله يرحم الوالدين عندي مشكل كبيييير و محتاجة ...    0   \n",
       "...          ...                                                ...  ...   \n",
       "6414          79                                 هدى  جمعاك شعر كحل    0   \n",
       "6415        3927                تفو.. على أغنية زملاوية بحال مولاها    1   \n",
       "6416        5955  كون خرجات ها.ي كالت انا كنشطح كون بان ليك مساع...    1   \n",
       "6417        6936                                       الفديو زوين.    0   \n",
       "6418        5640  مسكينة هدا ام الله ياكوان معها مسكينة يارب عفو...    0   \n",
       "\n",
       "                                          clean_comment  \\\n",
       "0     فنانين الكبت والفساد عقليه جنسيه العفن الفن شع...   \n",
       "1     الدعاره هربت المحمديه سكنت بوزنيقه بحال بحال م...   \n",
       "2                                كون خريتي مدرتيش هادشي   \n",
       "3     بالله العلي العظيم بالله العلي العظيم استغفرال...   \n",
       "4     الله يرحم الوالدين عندي مشكل كبيير محتاجه الدع...   \n",
       "...                                                 ...   \n",
       "6414                                  هدي جمعاك شعر كحل   \n",
       "6415                      تفو اغنيه زملاويه بحال مولاها   \n",
       "6416  كون خرجات هاي كالت انا كنشطح كون ليك مساعادات ...   \n",
       "6417                                        الفديو زوين   \n",
       "6418  مسكينه هدا ام الله ياكوان مسكينه يارب عفو بنته...   \n",
       "\n",
       "                                   clean_comment_nemoji  \n",
       "0     فنانين الكبت والفساد عقليه جنسيه العفن الفن شع...  \n",
       "1     الدعاره هربت المحمديه سكنت بوزنيقه بحال بحال م...  \n",
       "2                                كون خريتي مدرتيش هادشي  \n",
       "3     بالله العلي العظيم بالله العلي العظيم استغفرال...  \n",
       "4     الله يرحم الوالدين عندي مشكل كبيير محتاجه الدع...  \n",
       "...                                                 ...  \n",
       "6414                                  هدي جمعاك شعر كحل  \n",
       "6415                      تفو اغنيه زملاويه بحال مولاها  \n",
       "6416  كون خرجات هاي كالت انا كنشطح كون ليك مساعادات ...  \n",
       "6417                                        الفديو زوين  \n",
       "6418  مسكينه هدا ام الله ياكوان مسكينه يارب عفو بنته...  \n",
       "\n",
       "[6419 rows x 5 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>splitting the data into target and feature</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df1.clean_comment_nemoji\n",
    "Y_train = df1.off\n",
    "X_test = df2.clean_comment_nemoji\n",
    "Y_test = df2.off\n",
    "# splitting into train and tests\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(feature, target, test_size =.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect.fit(df1[\"clean_comment_nemoji\"])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(X_train)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6419, 23746)\n",
      "(1605, 23746)\n"
     ]
    }
   ],
   "source": [
    "print(Train_X_Tfidf.shape)\n",
    "print(Test_X_Tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vec = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> logistic regression </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   16.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7460    0.7782    0.7618       717\n",
      "           1     0.8145    0.7860    0.8000       888\n",
      "\n",
      "    accuracy                         0.7826      1605\n",
      "   macro avg     0.7802    0.7821    0.7809      1605\n",
      "weighted avg     0.7839    0.7826    0.7829      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make pipeline\n",
    "pipe = make_pipeline(tf_idf_vec, LogisticRegression())\n",
    "# make param grid\n",
    "param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# create and fit the model\n",
    "model = GridSearchCV(pipe, param_grid, cv=10, verbose=1)\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "# make prediction and print accuracy\n",
    "prediction = model.predict(X_test)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 10}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([clean('الزمر فالطوندونس هو باطمة تلاقيتو تواتيتو')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([clean('زي الهوا يا حبيبي زي الهوا')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SVM </h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed: 13.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7527    0.7727    0.7626       717\n",
      "           1     0.8124    0.7950    0.8036       888\n",
      "\n",
      "    accuracy                         0.7850      1605\n",
      "   macro avg     0.7826    0.7839    0.7831      1605\n",
      "weighted avg     0.7858    0.7850    0.7853      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(tf_idf_vec, SVC())\n",
    "param_grid = {'svc__kernel': ['rbf', 'linear', 'poly'],\n",
    "             'svc__gamma': [0.1, 1, 10, 100],\n",
    "             'svc__C': [0.1, 1, 10, 100]}\n",
    "\n",
    "svc_model = GridSearchCV(pipe, param_grid, cv=5, verbose=1)\n",
    "svc_model.fit(X_train, Y_train)\n",
    "\n",
    "prediction = svc_model.predict(X_test)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 100, 'svc__gamma': 1, 'svc__kernel': 'rbf'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.predict([clean('الزمر فالطوندونس هو باطمة تلاقيتو تواتيتو')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>  Random Forest Model </h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 17.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.78\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(tf_idf_vec, RandomForestClassifier())\n",
    "\n",
    "param_grid = {'randomforestclassifier__n_estimators':[10, 100, 1000],\n",
    "             'randomforestclassifier__max_features':['sqrt', 'log2']}\n",
    "\n",
    "rf_model = GridSearchCV(pipe, param_grid, cv=5, verbose=1)\n",
    "rf_model.fit(X_train,Y_train)\n",
    "\n",
    "prediction = rf_model.predict(X_test)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7450    0.7866    0.7653       717\n",
      "           1     0.8196    0.7827    0.8007       888\n",
      "\n",
      "    accuracy                         0.7844      1605\n",
      "   macro avg     0.7823    0.7846    0.7830      1605\n",
      "weighted avg     0.7863    0.7844    0.7849      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7477    0.7852    0.7660       717\n",
      "           1     0.8192    0.7860    0.8023       888\n",
      "\n",
      "    accuracy                         0.7857      1605\n",
      "   macro avg     0.7835    0.7856    0.7841      1605\n",
      "weighted avg     0.7873    0.7857    0.7861      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestclassifier__max_features': 'log2',\n",
       " 'randomforestclassifier__n_estimators': 1000}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.predict([clean('الزمر فالطوندونس هو باطمة تلاقيتو تواتيتو')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8205    0.6695    0.7373       717\n",
      "           1     0.7676    0.8818    0.8208       888\n",
      "\n",
      "    accuracy                         0.7869      1605\n",
      "   macro avg     0.7941    0.7756    0.7790      1605\n",
      "weighted avg     0.7913    0.7869    0.7835      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(tf_idf_vec, MultinomialNB())\n",
    "pipe.fit(X_train,Y_train)\n",
    "prediction = pipe.predict(X_test)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict([clean('الزمر فالطوندونس هو باطمة تلاقيتو تواتيتو')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_emoji(s):\n",
    "    return s in UNICODE_EMOJI['en']\n",
    "# add space near your emoji\n",
    "def add_space(text):\n",
    "    return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"clean_comment_emoji\"]=df1[\"clean_comment\"].apply(lambda row: add_space(row))\n",
    "df2[\"clean_comment_emoji\"]=df2[\"clean_comment\"].apply(lambda row: add_space(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>off</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>clean_comment_nemoji</th>\n",
       "      <th>clean_comment_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2908</td>\n",
       "      <td>فنانين الكبت والفساد .عقلية جنسية لا غير. العف...</td>\n",
       "      <td>1</td>\n",
       "      <td>فنانين الكبت والفساد عقليه جنسيه العفن الفن شع...</td>\n",
       "      <td>فنانين الكبت والفساد عقليه جنسيه العفن الفن شع...</td>\n",
       "      <td>فنانين الكبت والفساد عقليه جنسيه العفن الفن شع...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1055</td>\n",
       "      <td>الدعارة هربت منها في المحمدية و سكنت في بوزنيق...</td>\n",
       "      <td>1</td>\n",
       "      <td>الدعاره هربت المحمديه سكنت بوزنيقه بحال بحال م...</td>\n",
       "      <td>الدعاره هربت المحمديه سكنت بوزنيقه بحال بحال م...</td>\n",
       "      <td>الدعاره هربت المحمديه سكنت بوزنيقه بحال بحال م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181</td>\n",
       "      <td>كون غير خريتي و مدرتيش هادشي</td>\n",
       "      <td>1</td>\n",
       "      <td>كون خريتي مدرتيش هادشي</td>\n",
       "      <td>كون خريتي مدرتيش هادشي</td>\n",
       "      <td>كون خريتي مدرتيش هادشي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4313</td>\n",
       "      <td>لا حول ولا قوة الا بالله العلي العظيم لا حول و...</td>\n",
       "      <td>0</td>\n",
       "      <td>بالله العلي العظيم بالله العلي العظيم استغفرال...</td>\n",
       "      <td>بالله العلي العظيم بالله العلي العظيم استغفرال...</td>\n",
       "      <td>بالله العلي العظيم بالله العلي العظيم استغفرال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>الله يرحم الوالدين عندي مشكل كبيييير و محتاجة ...</td>\n",
       "      <td>0</td>\n",
       "      <td>الله يرحم الوالدين عندي مشكل كبيير محتاجه الدع...</td>\n",
       "      <td>الله يرحم الوالدين عندي مشكل كبيير محتاجه الدع...</td>\n",
       "      <td>الله يرحم الوالدين عندي مشكل كبيير محتاجه الدع...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>79</td>\n",
       "      <td>هدى  جمعاك شعر كحل</td>\n",
       "      <td>0</td>\n",
       "      <td>هدي جمعاك شعر كحل</td>\n",
       "      <td>هدي جمعاك شعر كحل</td>\n",
       "      <td>هدي جمعاك شعر كحل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>3927</td>\n",
       "      <td>تفو.. على أغنية زملاوية بحال مولاها</td>\n",
       "      <td>1</td>\n",
       "      <td>تفو اغنيه زملاويه بحال مولاها</td>\n",
       "      <td>تفو اغنيه زملاويه بحال مولاها</td>\n",
       "      <td>تفو اغنيه زملاويه بحال مولاها</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>5955</td>\n",
       "      <td>كون خرجات ها.ي كالت انا كنشطح كون بان ليك مساع...</td>\n",
       "      <td>1</td>\n",
       "      <td>كون خرجات هاي كالت انا كنشطح كون ليك مساعادات ...</td>\n",
       "      <td>كون خرجات هاي كالت انا كنشطح كون ليك مساعادات ...</td>\n",
       "      <td>كون خرجات هاي كالت انا كنشطح كون ليك مساعادات ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>6936</td>\n",
       "      <td>الفديو زوين.</td>\n",
       "      <td>0</td>\n",
       "      <td>الفديو زوين</td>\n",
       "      <td>الفديو زوين</td>\n",
       "      <td>الفديو زوين</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>5640</td>\n",
       "      <td>مسكينة هدا ام الله ياكوان معها مسكينة يارب عفو...</td>\n",
       "      <td>0</td>\n",
       "      <td>مسكينه هدا ام الله ياكوان مسكينه يارب عفو بنته...</td>\n",
       "      <td>مسكينه هدا ام الله ياكوان مسكينه يارب عفو بنته...</td>\n",
       "      <td>مسكينه هدا ام الله ياكوان مسكينه يارب عفو بنته...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6419 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                            comment  off  \\\n",
       "0           2908  فنانين الكبت والفساد .عقلية جنسية لا غير. العف...    1   \n",
       "1           1055  الدعارة هربت منها في المحمدية و سكنت في بوزنيق...    1   \n",
       "2            181                       كون غير خريتي و مدرتيش هادشي    1   \n",
       "3           4313  لا حول ولا قوة الا بالله العلي العظيم لا حول و...    0   \n",
       "4            228  الله يرحم الوالدين عندي مشكل كبيييير و محتاجة ...    0   \n",
       "...          ...                                                ...  ...   \n",
       "6414          79                                 هدى  جمعاك شعر كحل    0   \n",
       "6415        3927                تفو.. على أغنية زملاوية بحال مولاها    1   \n",
       "6416        5955  كون خرجات ها.ي كالت انا كنشطح كون بان ليك مساع...    1   \n",
       "6417        6936                                       الفديو زوين.    0   \n",
       "6418        5640  مسكينة هدا ام الله ياكوان معها مسكينة يارب عفو...    0   \n",
       "\n",
       "                                          clean_comment  \\\n",
       "0     فنانين الكبت والفساد عقليه جنسيه العفن الفن شع...   \n",
       "1     الدعاره هربت المحمديه سكنت بوزنيقه بحال بحال م...   \n",
       "2                                كون خريتي مدرتيش هادشي   \n",
       "3     بالله العلي العظيم بالله العلي العظيم استغفرال...   \n",
       "4     الله يرحم الوالدين عندي مشكل كبيير محتاجه الدع...   \n",
       "...                                                 ...   \n",
       "6414                                  هدي جمعاك شعر كحل   \n",
       "6415                      تفو اغنيه زملاويه بحال مولاها   \n",
       "6416  كون خرجات هاي كالت انا كنشطح كون ليك مساعادات ...   \n",
       "6417                                        الفديو زوين   \n",
       "6418  مسكينه هدا ام الله ياكوان مسكينه يارب عفو بنته...   \n",
       "\n",
       "                                   clean_comment_nemoji  \\\n",
       "0     فنانين الكبت والفساد عقليه جنسيه العفن الفن شع...   \n",
       "1     الدعاره هربت المحمديه سكنت بوزنيقه بحال بحال م...   \n",
       "2                                كون خريتي مدرتيش هادشي   \n",
       "3     بالله العلي العظيم بالله العلي العظيم استغفرال...   \n",
       "4     الله يرحم الوالدين عندي مشكل كبيير محتاجه الدع...   \n",
       "...                                                 ...   \n",
       "6414                                  هدي جمعاك شعر كحل   \n",
       "6415                      تفو اغنيه زملاويه بحال مولاها   \n",
       "6416  كون خرجات هاي كالت انا كنشطح كون ليك مساعادات ...   \n",
       "6417                                        الفديو زوين   \n",
       "6418  مسكينه هدا ام الله ياكوان مسكينه يارب عفو بنته...   \n",
       "\n",
       "                                    clean_comment_emoji  \n",
       "0     فنانين الكبت والفساد عقليه جنسيه العفن الفن شع...  \n",
       "1     الدعاره هربت المحمديه سكنت بوزنيقه بحال بحال م...  \n",
       "2                                كون خريتي مدرتيش هادشي  \n",
       "3     بالله العلي العظيم بالله العلي العظيم استغفرال...  \n",
       "4     الله يرحم الوالدين عندي مشكل كبيير محتاجه الدع...  \n",
       "...                                                 ...  \n",
       "6414                                  هدي جمعاك شعر كحل  \n",
       "6415                      تفو اغنيه زملاويه بحال مولاها  \n",
       "6416  كون خرجات هاي كالت انا كنشطح كون ليك مساعادات ...  \n",
       "6417                                        الفديو زوين  \n",
       "6418  مسكينه هدا ام الله ياكوان مسكينه يارب عفو بنته...  \n",
       "\n",
       "[6419 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''feature = df.clean_comment_emoji\n",
    "target = df.off'''\n",
    "X_train = df1.clean_comment_emoji\n",
    "Y_train = df1.off\n",
    "X_test = df2.clean_comment_emoji\n",
    "Y_test = df2.off\n",
    "# splitting into train and tests\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(feature, target, test_size =.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer()\n",
    "Tfidf_vect.fit(df1[\"clean_comment_emoji\"])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(X_train)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vec = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> logistic regression </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   24.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7470    0.7782    0.7623       717\n",
      "           1     0.8147    0.7872    0.8007       888\n",
      "\n",
      "    accuracy                         0.7832      1605\n",
      "   macro avg     0.7808    0.7827    0.7815      1605\n",
      "weighted avg     0.7844    0.7832    0.7835      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make pipeline\n",
    "pipe = make_pipeline(tf_idf_vec, LogisticRegression())\n",
    "# make param grid\n",
    "param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# create and fit the model\n",
    "model = GridSearchCV(pipe, param_grid, cv=10, verbose=1)\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "# make prediction and print accuracy\n",
    "prediction = model.predict(X_test)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 10}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([clean('الزمر فالطوندونس هو باطمة تلاقيتو تواتيتو')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([clean('زي الهوا يا حبيبي زي الهوا')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SVM </h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed: 21.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7531    0.7741    0.7634       717\n",
      "           1     0.8134    0.7950    0.8041       888\n",
      "\n",
      "    accuracy                         0.7857      1605\n",
      "   macro avg     0.7832    0.7846    0.7838      1605\n",
      "weighted avg     0.7864    0.7857    0.7859      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(tf_idf_vec, SVC())\n",
    "param_grid = {'svc__kernel': ['rbf', 'linear', 'poly'],\n",
    "             'svc__gamma': [0.1, 1, 10, 100],\n",
    "             'svc__C': [0.1, 1, 10, 100]}\n",
    "\n",
    "svc_model = GridSearchCV(pipe, param_grid, cv=5, verbose=1)\n",
    "svc_model.fit(X_train, Y_train)\n",
    "\n",
    "prediction = svc_model.predict(X_test)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7531    0.7741    0.7634       717\n",
      "           1     0.8134    0.7950    0.8041       888\n",
      "\n",
      "    accuracy                         0.7857      1605\n",
      "   macro avg     0.7832    0.7846    0.7838      1605\n",
      "weighted avg     0.7864    0.7857    0.7859      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 100, 'svc__gamma': 1, 'svc__kernel': 'rbf'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.predict([clean('الزمر فالطوندونس هو باطمة تلاقيتو تواتيتو')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>  Random Forest Model </h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 12.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.78\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(tf_idf_vec, RandomForestClassifier())\n",
    "\n",
    "param_grid = {'randomforestclassifier__n_estimators':[10, 100, 1000],\n",
    "             'randomforestclassifier__max_features':['sqrt', 'log2']}\n",
    "\n",
    "rf_model = GridSearchCV(pipe, param_grid, cv=5, verbose=1)\n",
    "rf_model.fit(X_train,Y_train)\n",
    "\n",
    "prediction = rf_model.predict(X_test)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7440    0.7741    0.7587       717\n",
      "           1     0.8114    0.7849    0.7979       888\n",
      "\n",
      "    accuracy                         0.7801      1605\n",
      "   macro avg     0.7777    0.7795    0.7783      1605\n",
      "weighted avg     0.7813    0.7801    0.7804      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestclassifier__max_features': 'log2',\n",
       " 'randomforestclassifier__n_estimators': 1000}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.predict([clean('الزمر فالطوندونس هو باطمة تلاقيتو تواتيتو')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8205    0.6695    0.7373       717\n",
      "           1     0.7676    0.8818    0.8208       888\n",
      "\n",
      "    accuracy                         0.7869      1605\n",
      "   macro avg     0.7941    0.7756    0.7790      1605\n",
      "weighted avg     0.7913    0.7869    0.7835      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(tf_idf_vec, MultinomialNB())\n",
    "pipe.fit(X_train,Y_train)\n",
    "prediction = pipe.predict(X_test)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict([clean('الزمر فالطوندونس هو باطمة تلاقيتو تواتيتو')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
